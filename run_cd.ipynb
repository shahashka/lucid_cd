{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shah38/Desktop/lucid_cd/lucid_env/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "from causallearn.search.ScoreBased.GES import ges\n",
    "import itertools\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from dagma.nonlinear import DagmaMLP, DagmaNonlinear\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   MYORG  WDR44  NSA2  MRPS26  PTGS2  IFT52  MAF  LOC105377627  DAPK3  MKNK2  \\\n",
      "0   1140   1618  3404    1157   2288   1550  128           190   5910   3456   \n",
      "1   1402   2213  5139    1574   1413   2219  118            73   5513   8203   \n",
      "2   1123   1785  4566    1190   1381   2008  138           252   5579   3954   \n",
      "3   1126   1386  3888    1012    539   1954   70           172   5282   3925   \n",
      "4    836   1487  2848     828   2276   1246   68           188   4821   2950   \n",
      "\n",
      "   ...  GNG12  ELOVL1  FAM171A1  PDE1C  ZNF22   RPSA  CD40  NOTCH2  IGFBP3  \\\n",
      "0  ...  31498    7852      8311   1410   2625  41014   424    8598     322   \n",
      "1  ...  27016    7743      7952    601   5038  49442  2387    8050     769   \n",
      "2  ...  38299    8736      9994   1516   2737  54805   334   11262     418   \n",
      "3  ...  29153    6684      8090   1225   2429  46397   474    7337     280   \n",
      "4  ...  25858    6523      6913   1251   2108  34177   330    7163     242   \n",
      "\n",
      "   radiation  \n",
      "0        0.0  \n",
      "1        0.0  \n",
      "2        0.0  \n",
      "3        0.0  \n",
      "4        0.0  \n",
      "\n",
      "[5 rows x 5887 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/cd_matrix_dA.csv\")\n",
    "X = df.values\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.27441481 -0.29823198 -1.37249679 ... -0.30968512 -0.85772296\n",
      "  -0.80903983]\n",
      " [ 1.80663918  2.27347858  1.15416539 ... -0.56367968  2.19446817\n",
      "  -0.80903983]\n",
      " [ 0.17499568  0.42357586  0.31971154 ...  0.92506217 -0.20221882\n",
      "  -0.80903983]\n",
      " ...\n",
      " [-1.33383594 -0.31984299  0.01971592 ...  0.0286653  -0.5709399\n",
      "   0.94387981]\n",
      " [-0.4039746  -0.40196484  1.32455126 ...  0.2947107   0.83566272\n",
      "   1.82033963]\n",
      " [-0.70808019 -0.9897844   0.30369236 ... -0.23274516  0.65813035\n",
      "   1.82033963]]\n"
     ]
    }
   ],
   "source": [
    "X_norm = StandardScaler().fit_transform(X)\n",
    "print(X_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n",
      "mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/230000.0 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "The operator 'aten::_linalg_slogdet.sign' is not currently implemented for the MPS device. If you want this op to be considered for addition please comment on https://github.com/pytorch/pytorch/issues/141287 and mention use-case, that resulted in missing op as well as commit hash 2236df1770800ffea5697b11b0bb0d910b2e59e1. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(eq_model.I.device)\n\u001b[32m      8\u001b[39m model = DagmaNonlinear(eq_model, dtype=torch.float, device=device) \u001b[38;5;66;03m# create the model for DAG learning\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m W_est = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda1\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.02\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda2\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.005\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# fit the model with L1 reg. (coeff. 0.02) and L2 reg. (coeff. 0.005)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/lucid_cd/lucid_env/lib/python3.13/site-packages/dagma/nonlinear.py:321\u001b[39m, in \u001b[36mDagmaNonlinear.fit\u001b[39m\u001b[34m(self, X, lambda1, lambda2, T, mu_init, mu_factor, s, warm_iter, max_iter, lr, w_threshold, checkpoint)\u001b[39m\n\u001b[32m    319\u001b[39m lr_decay = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    320\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m success \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m321\u001b[39m     success = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms_cur\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    322\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mlr_decay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpbar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpbar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m success \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m    324\u001b[39m         \u001b[38;5;28mself\u001b[39m.model.load_state_dict(model_copy.state_dict().copy())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/lucid_cd/lucid_env/lib/python3.13/site-packages/dagma/nonlinear.py:216\u001b[39m, in \u001b[36mDagmaNonlinear.minimize\u001b[39m\u001b[34m(self, max_iter, lr, lambda1, lambda2, mu, s, lr_decay, tol, pbar)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_iter):\n\u001b[32m    215\u001b[39m     optimizer.zero_grad()\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m     h_val = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mh_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m h_val.item() < \u001b[32m0\u001b[39m:\n\u001b[32m    218\u001b[39m         \u001b[38;5;28mself\u001b[39m.vprint(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mFound h negative \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mh_val.item()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m at iter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/lucid_cd/lucid_env/lib/python3.13/site-packages/dagma/nonlinear.py:85\u001b[39m, in \u001b[36mDagmaMLP.h_func\u001b[39m\u001b[34m(self, s)\u001b[39m\n\u001b[32m     83\u001b[39m fc1_weight = fc1_weight.view(\u001b[38;5;28mself\u001b[39m.d, -\u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.d)\n\u001b[32m     84\u001b[39m A = torch.sum(fc1_weight ** \u001b[32m2\u001b[39m, dim=\u001b[32m1\u001b[39m).t()  \u001b[38;5;66;03m# [i, j]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m h = -\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mslogdet\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mI\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m] + \u001b[38;5;28mself\u001b[39m.d * np.log(s)\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m h\n",
      "\u001b[31mNotImplementedError\u001b[39m: The operator 'aten::_linalg_slogdet.sign' is not currently implemented for the MPS device. If you want this op to be considered for addition please comment on https://github.com/pytorch/pytorch/issues/141287 and mention use-case, that resulted in missing op as well as commit hash 2236df1770800ffea5697b11b0bb0d910b2e59e1. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS."
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "print(device)\n",
    "d = X_norm.shape[1]\n",
    "X_norm_tensor = torch.from_numpy(X).type(torch.float).to(device)\n",
    "eq_model = DagmaMLP(dims=[d, 10, 1], bias=True, dtype=torch.float) # create the model for the structural equations, in this case MLPs\n",
    "eq_model = eq_model.to(device)\n",
    "print(eq_model.I.device)\n",
    "model = DagmaNonlinear(eq_model, dtype=torch.float, device=device) # create the model for DAG learning\n",
    "W_est = model.fit(X_norm, lambda1=0.02, lambda2=0.005) # fit the model with L1 reg. (coeff. 0.02) and L2 reg. (coeff. 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lucid_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
